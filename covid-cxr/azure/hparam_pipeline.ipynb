{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Hyperparameter Search Pipeline for COVID-CXR\n",
    "This notebook defines an Azure machine learning pipeline for a hyperparameter search and submits the pipeline as an experiment to be run on an Azure virtual machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import azureml.core\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Workspace, Datastore\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep, HyperDriveStep, HyperDriveStepRun\n",
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive import choice, uniform, loguniform\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.widgets import RunDetails\n",
    "import shutil\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "CT_NAME = \"nd12s-clust1\"            # Name of our compute cluster\n",
    "VM_SIZE = \"STANDARD_ND12S\"          # Specify the Azure VM for execution of our pipeline\n",
    "MIN_NODES = 10\n",
    "MAX_NODES = 10                      # Max number of compute nodes in cluster\n",
    "TOTAL_RUNS = 100                    # Total training runs in hyperparameter search\n",
    "MAX_DURATION_MINUTES = 12 * 60      # Max # minutes to run the experiment for. (# hours * 60 min/hour)\n",
    "PRIMARY_METRIC = 'validation_auc'   # Primary metric for optimization in hyperparameter search\n",
    "WARM_START_RUNS = []                # List of HyperDriveRuns already ran to guide this experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the workspace and configure its Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reference to the workspace\n",
    "ws = Workspace.from_config(\"./ws_config.json\")\n",
    "\n",
    "# Set workspace's environment\n",
    "env = Environment.from_pip_requirements(name = \"covid-cxr_env\", file_path = \"./../requirements.txt\")\n",
    "env.register(workspace=ws)\n",
    "runconfig = RunConfiguration(conda_dependencies=env.python.conda_dependencies)\n",
    "print(env.python.conda_dependencies.serialize_to_string())\n",
    "\n",
    "# Move AML ignore file to root folder\n",
    "aml_ignore_path = shutil.copy('./.amlignore', './../.amlignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create references to persistent and intermediate data\n",
    "Create DataReference objects that point to our raw data on the blob. Configure a PipelineData object to point to preprocessed images stored on the blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the blob datastore associated with this workspace\n",
    "blob_store = Datastore(ws, name='covid_cxr_ds')\n",
    "\n",
    "# Create data references to folders on the blob\n",
    "raw_data_dr = DataReference(\n",
    "    datastore=blob_store,\n",
    "    data_reference_name=\"raw_data\",\n",
    "    path_on_datastore=\"data/\")\n",
    "mila_data_dr = DataReference(\n",
    "    datastore=blob_store,\n",
    "    data_reference_name=\"mila_data\",\n",
    "    path_on_datastore=\"data/covid-chestxray-dataset/\")\n",
    "fig1_data_dr = DataReference(\n",
    "    datastore=blob_store,\n",
    "    data_reference_name=\"fig1_data\",\n",
    "    path_on_datastore=\"data/Figure1-COVID-chestxray-dataset/\")\n",
    "rsna_data_dr = DataReference(\n",
    "    datastore=blob_store,\n",
    "    data_reference_name=\"rsna_data\",\n",
    "    path_on_datastore=\"data/rsna/\")\n",
    "\n",
    "# Set up references to pipeline data (intermediate pipeline storage).\n",
    "processed_pd = PipelineData(\n",
    "    \"processed_data\",\n",
    "    datastore=blob_store,\n",
    "    output_name=\"processed_data\")\n",
    "metrics_pd = PipelineData(\n",
    "    name='hparam_metrics_data',\n",
    "    datastore=blob_store,\n",
    "    pipeline_output_name=\"hparam_metric_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Target\n",
    "Specify and configure the compute target for this workspace. If a compute cluster by the name we specified does not exist, create a new compute cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the compute target for this\n",
    "try:\n",
    "    compute_target = AmlCompute(ws, CT_NAME)\n",
    "    print(\"Found existing compute target.\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new compute target\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=VM_SIZE,\n",
    "                                                                min_nodes=MIN_NODES, \n",
    "                                                                max_nodes=MAX_NODES)    \n",
    "    compute_target = ComputeTarget.create(ws, CT_NAME, provisioning_config)  # Create the compute cluster\n",
    "    \n",
    "    # Wait for cluster to be provisioned\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20) \n",
    "    \n",
    "print(\"Azure Machine Learning Compute attached\")\n",
    "print(\"Compute targets: \", ws.compute_targets)\n",
    "compute_target = ws.compute_targets[CT_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure hyperparameter search experiment\n",
    "We will launch multiple runs on out compute cluster to run our hyperparameter search. Below we define the ranges over which to search for hyperparameters. We will randomly sample over the defined range and pass the samples to each training run as arguments to the training script. Then we specify the primary metric to optimize. Finally, we specify a termination policy, to prevent resource wastage during poorly performing runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define random sampling ranges\n",
    "param_sampling = RandomParameterSampling( {\n",
    "        \"KERNEL_SIZE\": choice('(3,3)', '(5,5)'), \n",
    "        \"MAXPOOL_SIZE\": choice('(2,2)', '(3,3)'),\n",
    "        \"INIT_FILTERS\": choice(8, 16, 32),\n",
    "        \"FILTER_EXP_BASE\": choice(range(2, 3)),\n",
    "        \"CONV_BLOCKS\": choice(range(3, 9)),\n",
    "        \"NODES_DENSE0\": choice(128, 256, 512, 1024),\n",
    "        \"LR\": loguniform(math.log(1e-5), math.log(1e-3)),\n",
    "        \"OPTIMIZER\": choice('adam'),\n",
    "        \"DROPOUT\": choice(0.0, 0.1, 0.2, 0.3, 0.4, 0.5),\n",
    "        \"L2_LAMBDA\": choice(0.0, 0.00001, 0.0001, 0.001),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Specify how we would like to optimize our primary metric\n",
    "primary_metric_goal = PrimaryMetricGoal.MINIMIZE if 'loss' in PRIMARY_METRIC else PrimaryMetricGoal.MAXIMIZE\n",
    "\n",
    "# Set termination policy\n",
    "early_termination_policy = BanditPolicy(slack_factor = 0.15, evaluation_interval=3, delay_evaluation=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define pipeline and submit experiment.\n",
    "Define the steps of an Azure machine learning pipeline. Create an Azure Experiment that will run our pipeline. Submit the experiment to the execution environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing step the ML pipeline\n",
    "step1 = PythonScriptStep(name=\"preprocess_step\",\n",
    "                         script_name=\"azure/preprocess_step/preprocess_step.py\",\n",
    "                         arguments=[\"--miladatadir\", mila_data_dr, \"--fig1datadir\", fig1_data_dr, \n",
    "                                    \"--rsnadatadir\", rsna_data_dr, \"--preprocesseddir\", processed_pd],\n",
    "                         inputs=[mila_data_dr, fig1_data_dr, rsna_data_dr],\n",
    "                         outputs=[processed_pd],\n",
    "                         compute_target=compute_target, \n",
    "                         source_directory=\"./../\",\n",
    "                         runconfig=runconfig,\n",
    "                         allow_reuse=True)\n",
    "\n",
    "# Define hyperparameter search step in the ML pipeline\n",
    "est = TensorFlow(source_directory='./../',\n",
    "                   script_params=None,\n",
    "                   compute_target=compute_target,\n",
    "                   entry_script='azure/hparam_train_step/hparam_train_step.py',\n",
    "                   pip_packages=['tensorboard', 'pandas', 'dill', 'numpy', 'imblearn', 'matplotlib', 'scikit-image', 'matplotlib',\n",
    "                                'pydicom', 'opencv-python', 'tqdm', 'scikit-learn'],\n",
    "                   use_gpu=True,\n",
    "                   framework_version='2.0')\n",
    "hd_config = HyperDriveConfig(estimator=est, \n",
    "                             hyperparameter_sampling=param_sampling,\n",
    "                             policy=early_termination_policy,\n",
    "                             primary_metric_name=PRIMARY_METRIC, \n",
    "                             primary_metric_goal=primary_metric_goal, \n",
    "                             max_total_runs=TOTAL_RUNS,\n",
    "                             max_concurrent_runs=MAX_NODES,\n",
    "                             max_duration_minutes=MAX_DURATION_MINUTES,\n",
    "                             resume_from=WARM_START_RUNS)\n",
    "step2 = HyperDriveStep(name=\"hyperdrive_step\",\n",
    "                       hyperdrive_config=hd_config,\n",
    "                       estimator_entry_script_arguments=[\"--rawdatadir\", raw_data_dr, \"--preprocesseddir\", processed_pd],\n",
    "                       inputs=[raw_data_dr, processed_pd],\n",
    "                       metrics_output=metrics_pd)\n",
    "\n",
    "# Construct the ML pipeline from the steps\n",
    "steps = [step1, step2]\n",
    "hparams_pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "hparams_pipeline.validate()\n",
    "\n",
    "# Define a new experiment and submit a new pipeline run to the compute target.\n",
    "experiment = Experiment(workspace=ws, name='HyperDriveExperiment_v1')\n",
    "hyperdrive_run = experiment.submit(hparams_pipeline, regenerate_outputs=False)\n",
    "print(\"HyperDrive pipeline is submitted for execution\")\n",
    "\n",
    "# Move AML ignore file back to original folder\n",
    "aml_ignore_path = shutil.move(aml_ignore_path, './.amlignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve results\n",
    "Get the metrics of the pipeline run and download them to the local project. Then get the file name of the model with the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the pipeline to finish running.\n",
    "hyperdrive_run.wait_for_completion()\n",
    "\n",
    "# Use the Azure RunDetails widget to view results of the hyperparameter search\n",
    "hd_step_run = HyperDriveStepRun(step_run=hyperdrive_run.find_step_run(\"hyperdrive_step\")[0])\n",
    "RunDetails(hd_step_run).show()\n",
    "best_run = hd_step_run.get_best_run_by_primary_metric()\n",
    "\n",
    "# Download the metrics from the hyperparameter search experiment.\n",
    "metrics_output = hyperdrive_run.get_pipeline_output(\"hparam_metric_data\")\n",
    "num_file_downloaded = metrics_output.download('./../results/logs/hparam_search/', show_progress=True)\n",
    "\n",
    "# Print all metrics from the best run\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "print(\"Best model's metrics:\")\n",
    "for metric_name in best_run_metrics:\n",
    "    print(str(metric_name) + ': ' + str(best_run_metrics[metric_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
